



# Chat With Website ğŸ”ğŸ¤–

This project is a **Retrieval-Augmented Generation (RAG)** system built with **Google Gemini**, **ChromaDB**, and **Streamlit**. It allows users to **crawl any website**, index its content, and then **ask natural language questions** based on the scraped content â€” all through a clean Streamlit UI.

---

## ğŸš€ Features

- ğŸŒ Crawl and scrape any website (up to a user-defined page limit)
- ğŸ“„ Extract clean, readable text (removes scripts/styles)
- ğŸ§  Index documents into a vector store using Sentence Transformers
- ğŸ” Query top-matching chunks from the vector store
- ğŸ¤– Get answers using Gemini (via `gemini-1.5-flash`)
- ğŸ–¥ï¸ Simple, interactive Streamlit interface

---

## ğŸ› ï¸ Tech Stack

| Tool | Purpose |
|------|---------|
| `requests` | Download webpage content |
| `BeautifulSoup` | Parse and clean HTML/XML |
| `ChromaDB` | Lightweight vector store |
| `SentenceTransformers` | Embed text chunks for retrieval |
| `Google Generative AI` | Gemini for answering user queries |
| `Streamlit` | Web-based UI |

---

## ğŸ“¦ Installation

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/gemini-rag-web-crawler.git
cd gemini-rag-web-crawler
````

### 2. Set up a virtual environment (recommended)

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure your Gemini API key

Create a `.env` file in the root directory:

```
GEMINI_API_KEY=your_gemini_api_key_here
```

You can get your API key from the [Google AI Studio](https://makersuite.google.com/app/apikey).

---

## â–¶ï¸ Running the App

```bash
streamlit run app.py
```

---

## ğŸ§  How It Works

### ğŸ” Crawling (`crawler.py`)

* Starts from a root URL and crawls internal pages (BFS).
* Filters out non-text elements (like `<script>` or `<style>`).
* Stops after a user-specified number of pages.

### ğŸ“š Indexing (`rag.py`)

* Splits text into manageable chunks (\~500 words).
* Embeds them using `all-MiniLM-L6-v2`.
* Stores them in a local ChromaDB collection (`web_docs`).

### â“ Question Answering (`rag.py`)

* Takes a natural language query.
* Retrieves top 5 relevant chunks from the vector DB.
* Sends the query and context to Gemini to generate an answer.

### ğŸ–¥ï¸ Frontend (`app.py`)

* User enters the URL and page limit.
* Clicks "Crawl Website" to begin indexing.
* Then types a question and gets answers from Gemini based on the crawled content.

---

## ğŸ§ª Example Use Case

* URL: `https://scikit-learn.org`
* Question: *"What is GridSearchCV used for?"*
* Gemini responds with a summarized answer based on the actual content of the website.

---

## âœ… Tips for Best Results

* Use websites with clear navigation and accessible content (no login required).
* Set a reasonable `max_pages` limit (e.g., 5â€“20) to keep things responsive.
* Ask specific, contextual questions after crawling.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py             # Streamlit frontend
â”œâ”€â”€ crawler.py         # BFS website crawler
â”œâ”€â”€ rag.py             # Embedding + Gemini query logic
â”œâ”€â”€ .env               # Gemini API key (not committed)
â”œâ”€â”€ requirements.txt   # Python dependencies
â””â”€â”€ README.md          # Project documentation
```
